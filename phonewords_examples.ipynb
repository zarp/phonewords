{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phoneword generation: explanation & usage examples\n",
    "\n",
    "### Prep work\n",
    "\n",
    "First, we'll need a list of valid English words. We will pull it from NLTK 'words' corpus. We can also filter our very short words like \"I\", \"AM\", \"BE\" by setting min_vocab_word_len to some value above 1. Such short words tend to be not very meaningful for creating useful phonewords. A helper function find_valid_word() will be used to extract words from this vocabulary using regular expressions. \n",
    "\n",
    "Finally, we'll specify mapping between numbers and digits on phone's keypad. For convenience sake, we'll also map each digit to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SNOWFOWL', 'SNOW', 'SNOWCAP', 'SNOWBREAK', 'SNOWLESS', 'SNOWBOUND', 'SNOWISH', 'SNOWBERRY', 'SNOWY', 'SNOWFLIGHT', 'SNOWSHOED', 'SNOWHOUSE', 'SNOWL', 'SNOWPLOW', 'SNOWBUSH', 'SNOWBERG', 'SNOWSHOE', 'SNOWSUIT', 'SNOWINESS', 'SNOWSLIDE', 'SNOWSHINE', 'SNOWBLINK', 'SNOWMOBILE', 'SNOWSHOER', 'SNOWBALL', 'SNOWMANSHIP', 'SNOWLIKE', 'SNOWSHED', 'SNOWDRIFT', 'SNOWILY', 'SNOWFALL', 'SNOWSTORM', 'SNOWDONIAN', 'SNOWSCAPE', 'SNOWSHOEING', 'SNOWCRAFT', 'SNOWSHADE', 'SNOWLAND', 'SNOWK', 'SNOWFLOWER', 'SNOWIE', 'SNOWSLIP', 'SNOWWORM', 'SNOWBANK', 'SNOWFLAKE', 'SNOWHAMMER', 'SNOWPROOF', 'SNOWBELL', 'SNOWDROP', 'SNOWBIRD'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import words\n",
    "\n",
    "def get_english_vocabulary(min_vocab_word_len):\n",
    "    \"\"\" Use nltk.words word list,  words shorter than min_vocab_word_len will be excluded.\"\"\"\n",
    "    try:\n",
    "        vocab = set([word.upper() for word in words.words() if len(word) >= min_vocab_word_len])\n",
    "    except:\n",
    "        print(\"NLTK 'words' corpus not found. Downloading...\")\n",
    "        import nltk\n",
    "        nltk.download('words')\n",
    "        vocab = set([word.upper() for word in words.words() if len(word) >= min_vocab_word_len])\n",
    "            \n",
    "    return vocab\n",
    "\n",
    "\n",
    "def find_valid_word(regexp, vocab, get_all_words = False):\n",
    "    \"\"\"  Output either a single valid English word or a set of all English words matching input regex string. \"\"\"\n",
    "    all_words = set()\n",
    "    for word in vocab: \n",
    "        hit = re.match(regexp, word.upper())\n",
    "        if hit is not None:\n",
    "            if not get_all_words: return word.upper()\n",
    "            all_words.add(word.upper())\n",
    "    return all_words\n",
    "\n",
    "mapping = {\"1\": [\"1\"],\n",
    "           \"2\": [\"A\",\"B\",\"C\",\"2\"],\n",
    "           \"3\": [\"D\",\"E\",\"F\",\"3\"],\n",
    "           \"4\": [\"G\",\"H\",\"I\",\"4\"],\n",
    "           \"5\": [\"J\",\"K\",\"L\",\"5\"],\n",
    "           \"6\": [\"M\",\"N\",\"O\",\"6\"],\n",
    "           \"7\": [\"P\",\"Q\",\"R\",\"S\",\"7\"],\n",
    "           \"8\": [\"T\",\"U\",\"V\", \"8\"],\n",
    "           \"9\": [\"W\",\"X\",\"Y\",\"Z\", \"9\"],\n",
    "           \"0\": [\"0\"]}\n",
    "\n",
    "vocabulary = get_english_vocabulary(min_vocab_word_len = 3)\n",
    "words_starting_with_snow = find_valid_word('^SNOW.*', vocabulary, get_all_words = True)\n",
    "print(words_starting_with_snow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>words_to_number()</b> uses inverse mapping dict lookup to convert phonewords back to proper phone numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-800-HAMSTER  <->  1-800-426-7837\n",
      "1-800-PAINTER  <->  1-800-724-6837\n"
     ]
    }
   ],
   "source": [
    "def words_to_number(wordified, mapping):\n",
    "    \"\"\" Reverse of number_to_words(). \"\"\"\n",
    "    reversed_num = \"\"\n",
    "    for ch in wordified.replace(\"-\",\"\").upper():\n",
    "        reversed_num +=  next(key for key, val in mapping.items() if ch in val)\n",
    "            \n",
    "    return reversed_num[0] + '-' + reversed_num[1:4] + \"-\" + reversed_num[4:7] + \"-\" + reversed_num[7:]\n",
    "\n",
    "test_strings = [\"1-800-HAMSTER\", \"1-800-PAINTER\"]\n",
    "for string in test_strings:\n",
    "    print(string, ' <-> ', words_to_number(string, mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single phone number can be wordified in many different ways, <b>number_to_words()</b> will return only the first wordification it finds as follows:\n",
    "\n",
    "input string -> substrings -> regexes -> english_words (stop when found 1) -> wordified_string\n",
    "\n",
    "The print statement near the bottom of the function can be uncommented to show these intermediate steps. \n",
    "\n",
    "Also note that we can specify minimal word length that can be higher than min length in our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-800-724-6837  <->  1800724OVER\n",
      "1-111-111-1111  <->  11111111111\n"
     ]
    }
   ],
   "source": [
    "def number_to_words(num, vocab, mapping, min_word_len = 1):\n",
    "    \"\"\" Convert str representing phone number to wordified str. If no valid wordifications exist - return original digits. \"\"\"\n",
    "    def find_usable_substrings(num_str, min_len = 1):\n",
    "        \"\"\" Find substr of num_str and furter split them on chars that can't be converted to letters('1' and '0'). \"\"\"   \n",
    "        num_len, subs = len(num_str), set()\n",
    "        \n",
    "        for i in range(num_len):\n",
    "            subs = subs.union([num_str[i:j + 1] for j in range(i + min_len - 1, num_len)])\n",
    "        \n",
    "        for el in subs.copy():\n",
    "            if (\"1\" in el) or (\"0\" in el):\n",
    "                subs.remove(el)\n",
    "                subs.union(el.replace(\"1\", \"0\").split(\"0\"))\n",
    "            return subs\n",
    "\n",
    "    wordified = num.replace(\"-\",\"\")\n",
    "    subs = find_usable_substrings(wordified, min_len = min_word_len)\n",
    "    \n",
    "    while len(subs)>0:\n",
    "        substr = subs.pop()\n",
    "        reg = \"^\" + \"\".join([\"[\" + \"\".join(mapping[ch]) + \"]\" for ch in substr]).replace(\"[-]\",\"\") + \"$\"\n",
    "        word = find_valid_word(reg, vocab)\n",
    "        if word == set(): word = None\n",
    "        if word is not None: \n",
    "            wordified = wordified.replace(substr, word) #will replace all copies of substr if >1 present. Spec didn't specify desired behavior so leaving this as-is\n",
    "            #print(substr.rjust(12),'<->', reg.rjust(50), '<->', str(word).rjust(12),'<->', wordified.rjust(12)) #uncomment to see intermediate steps\n",
    "            break\n",
    "\n",
    "    return wordified\n",
    "\n",
    "test_strings = [\"1-800-724-6837\", \"1-111-111-1111\"]\n",
    "for string in test_strings:\n",
    "    print(string, ' <-> ', number_to_words(string, vocabulary, mapping, min_word_len = 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function returns all possible wordifications (incl. multiple wordifications per phone number). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Printing output (if minimal word size was set to 1 it may take some time):\n",
      "\n",
      "{'18007AHOUDS', '18007AINU37', '1800RAH6837', '1800PAH6UDS', '1800RAHMUD7', '1800SAIOVER', '1800SAIOUF7', '1800SAHOVER', '1800RAIN837', '1800PAHOUF7', '180072HOVER', '18007CINTER', '18007AGOUDS', '180072IMU37', '1800RAG6837', '1800SAGOUF7', '1800RAGMUD7', '1800724OVER', '1800RAHOUF7', '1800SAGO837', '1800SAHO837', '18007BINUDS', '1800SCHO837', '1800PAHOUDS', '1800SAG6837', '1800SAIMUDS', '1800PAH6837', '1800SAIM837', '18007CHO837', '1800PAINT37', '18007BIM837', '1800PAINTER', '18007AIMUDS', '18007AGO837', '180072GOTE7', '18007AIM837', '18007CHOUDS', '180072HOVE7', '1800SAGMUD7', '1800RAGOUF7', '1800724MUD7', '180072HOT37', '180072GNU37', '180072INTER', '1800SAHMUD7', '1800SAG6UDS', '1800SCIOT37', '1800RAHOVER', '1800PAHMUD7', '1800PAHO837', '1800SAH6837', '1800RAINUDS', '18007AINT37', '18007BINT37', '1800RAH6UDS', '1800SCHOUDS', '1800SAINT37', '1800724OUF7', '18007246UDS', '180072GOVE7', '18007CHOU37', '1800SAGOVER', '1800SAINUDS', '1800RAGOVER', '1800PAIN837', '1800RAG6UDS', '1800SAIMUD7', '1800PAINUDS', '1800SAIN837', '18007BIN837', '18007AHO837', '18007BIMUDS', '1800SAHOUF7', '1800SAGOUDS', '1800SAI6UDS', '1800SAHOUDS', '1800SAH6UDS', '18007246837', '1800SAI6837', '1800PAHOVER', '180072GOT37'}\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "def all_wordifications(num, vocab, mapping):\n",
    "    \"\"\" Output all possible combinations of numbers and English words in a phone number. \"\"\"\n",
    "    \n",
    "    def gen_partitions(num_str):\n",
    "        \"\"\" Generate all possible partitions of a string into constituent substrings. \"\"\"\n",
    "        for i in range(len(num_str)):\n",
    "            if i == len(num_str) - 1:\n",
    "                yield num_str\n",
    "\n",
    "            first, rest = num_str[0:i+1], num_str[i+1:]\n",
    "\n",
    "            for j in gen_partitions(rest):\n",
    "                yield '~'.join([first, j])\n",
    "                \n",
    "    num = num.replace(\"-\",\"\")\n",
    "\n",
    "    subs_dict, ans = dict(), set()\n",
    "    for partition in gen_partitions(num):\n",
    "        subs = partition.split('~')\n",
    "\n",
    "        for sub in subs:\n",
    "            #adding dict entries for previously not encountered substrings\n",
    "            if sub not in subs_dict:\n",
    "                if (\"1\" in sub) or (\"0\" in sub):\n",
    "                    subs_dict[sub] = set()\n",
    "                else:\n",
    "                    reg = \"^\" + \"\".join([\"[\" + \"\".join(mapping[ch]) + \"]\" for ch in sub]) + \"$\" \n",
    "                    subs_dict[sub] = find_valid_word(reg, vocab, get_all_words = True)\n",
    "                subs_dict[sub].add(sub)\n",
    "\n",
    "        combos = product(*[subs_dict[el] for el in subs])\n",
    "        \n",
    "        for c in combos:\n",
    "            ans.add(\"\".join(c))\n",
    "            \n",
    "    return ans\n",
    "\n",
    "test_string = \"1-800-724-6837\"\n",
    "all_words = all_wordifications(test_string, vocabulary, mapping)\n",
    "print(\"Done! Printing output (if minimal word size was set to 1 it may take some time):\\n\")\n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If some of these words don't look familiar, it is due to one of two reasons: \n",
    "1. Two (or more) neighboring wordifications looking like one word (e.g. GNUMAD = GNU + MAD).\n",
    "2. words.words() corpus containing some unusual/odd words. As a quick sanity check we can verify that they are indeed valid words according to that dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word GOVE in vocabulary: True\n",
      "word SAH in vocabulary: True\n",
      "word OUF in vocabulary: True\n",
      "word OBVIOUSLYFAKEWORD in vocabulary: False\n"
     ]
    }
   ],
   "source": [
    "unusual_words = ['GOVE', 'SAH', 'OUF',  'OBVIOUSLYFAKEWORD']\n",
    "for word in unusual_words:\n",
    "    print('word', word, 'in vocabulary:', word in vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If necessary - the number of these unusual words can be reduced by increasing min_vocab_word_len and/or by using a different vocabulary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
